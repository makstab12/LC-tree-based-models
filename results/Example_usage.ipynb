{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example analysis of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries i funkcje (do wczytania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from math import ceil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista zawierająca rozmiar anchorów\n",
    "anchor_list_denser = np.ceil(16 * 2 ** ((np.arange(70)) / 8)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do obliczania wartości całki dla krzywej uczenia\n",
    "def LC_integral_value(y_array):\n",
    "    # y_array powinno być ndarrat\n",
    "    # x_values odpowiada anchor_list_denser\n",
    "    x_values = np.ceil(16 * 2 ** ((np.arange(70)) / 8)).astype(float)\n",
    "    # Indeks pierwszego NaN w y_array\n",
    "    valid_length = np.argmax(np.isnan(y_array)) if np.isnan(y_array).any() else len(y_array)\n",
    "    \n",
    "    # Ogranicz dane tylko do fragmentu bez NaN\n",
    "    y = y_array[:valid_length]\n",
    "    x = x_values[:valid_length]\n",
    "    \n",
    "    # Unormowanie x do przedziału [0, 1]\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "    integral = np.trapz(y, x_norm)\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wczytanie pliku csv i przekształcenie ramki danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WYPEŁNIĆ ### \n",
    "# ścieżka do pliku csv, który ma być wczytany\n",
    "input_file = \"__RESULTS_DT__.csv\"\n",
    "# Wczytujemy wyniki dla modelu Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ten kod wczytuje dane z pliku CSV i przekształca do ramki danych transformed_df, którą można dalej wykorzystać do analizy\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Pusta lista na przekształcone dane\n",
    "transformed_data = []\n",
    "\n",
    "grouped = df.groupby(['Dataset_name', 'Preprocessing_method', 'Hyperparameters'], sort = False)\n",
    "# sort = False, aby zachować domyślną kolejność, a nie alfabetycznie\n",
    "for (dataset_name, preprocessing_method, hyperparameters), group in grouped:\n",
    "    hyperparameters = json.loads(hyperparameters)\n",
    "    \n",
    "    outer_splits = 5\n",
    "    inner_splits = 5\n",
    "    train_val_test_splits = 3\n",
    "    scores_size = 70\n",
    "\n",
    "    results = np.full((outer_splits, inner_splits, scores_size, train_val_test_splits), np.nan)\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        i = int(row['Outer_split'])\n",
    "        j = int(row['Inner_split'])\n",
    "        k = int(row['Train-val-test'])\n",
    "        scores = np.array(json.loads(row['Scores']))\n",
    "        results[i, j, :, k] = scores\n",
    "    \n",
    "    transformed_data.append({\n",
    "        'Dataset Name': dataset_name,\n",
    "        'Preprocessing Method': preprocessing_method,\n",
    "        'Hyperparameters': hyperparameters,\n",
    "        'Results': results\n",
    "    })\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Odczytywanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Preprocessing Method</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.23387097 0.19565217], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 6, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.16935484 0.10144928], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 28, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5        0.44354839 0.44202899], [0.4444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5        0.44354839 0.44202899], [0.4444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5        0.44354839 0.44202899], [0.5   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 15, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.25 0.3  0.3 ], [0.27777778 0.3        0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 52, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5 0.3 0.3], [0.44444444 0.3        0.3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 8, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.125      0.36666667 0.32      ], [0.1111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 14, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.0625     0.24444444 0.34      ], [0.2222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 6, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.38888889 0.39      ], [0.0555...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset Name Preprocessing Method  \\\n",
       "0    banknote-authentication          unprocessed   \n",
       "1    banknote-authentication          unprocessed   \n",
       "2    banknote-authentication          unprocessed   \n",
       "3    banknote-authentication          unprocessed   \n",
       "4    banknote-authentication          unprocessed   \n",
       "..                       ...                  ...   \n",
       "485             credit-g-mod         med_knn_none   \n",
       "486             credit-g-mod         med_knn_none   \n",
       "487             credit-g-mod         med_knn_none   \n",
       "488             credit-g-mod         med_knn_none   \n",
       "489             credit-g-mod         med_knn_none   \n",
       "\n",
       "                                       Hyperparameters  \\\n",
       "0    {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "1    {'min_samples_split': 6, 'min_samples_leaf': 1...   \n",
       "2    {'min_samples_split': 28, 'min_samples_leaf': ...   \n",
       "3    {'min_samples_split': 20, 'min_samples_leaf': ...   \n",
       "4    {'min_samples_split': 50, 'min_samples_leaf': ...   \n",
       "..                                                 ...   \n",
       "485  {'min_samples_split': 15, 'min_samples_leaf': ...   \n",
       "486  {'min_samples_split': 52, 'min_samples_leaf': ...   \n",
       "487  {'min_samples_split': 8, 'min_samples_leaf': 1...   \n",
       "488  {'min_samples_split': 14, 'min_samples_leaf': ...   \n",
       "489  {'min_samples_split': 6, 'min_samples_leaf': 1...   \n",
       "\n",
       "                                               Results  \n",
       "0    [[[[0.         0.23387097 0.19565217], [0.    ...  \n",
       "1    [[[[0.         0.16935484 0.10144928], [0.    ...  \n",
       "2    [[[[0.5        0.44354839 0.44202899], [0.4444...  \n",
       "3    [[[[0.5        0.44354839 0.44202899], [0.4444...  \n",
       "4    [[[[0.5        0.44354839 0.44202899], [0.5   ...  \n",
       "..                                                 ...  \n",
       "485  [[[[0.25 0.3  0.3 ], [0.27777778 0.3        0....  \n",
       "486  [[[[0.5 0.3 0.3], [0.44444444 0.3        0.3  ...  \n",
       "487  [[[[0.125      0.36666667 0.32      ], [0.1111...  \n",
       "488  [[[[0.0625     0.24444444 0.34      ], [0.2222...  \n",
       "489  [[[[0.         0.38888889 0.39      ], [0.0555...  \n",
       "\n",
       "[490 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df\n",
    "# Zawiera kolumny\n",
    "# 'Dataset Name', 'Preprocessing Method', 'Hyperparameters', 'Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['banknote-authentication', 'blood-transfusion', 'breast_w',\n",
       "       'credit-approval', 'credit_g', 'diabetes', 'kr_vs_kp', 'phoneme',\n",
       "       'phoneme-mod', 'credit-g-mod'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nazwy zbiorów\n",
    "transformed_df['Dataset Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unprocessed', 'min_knn_BORUTA', 'min_knn_MI', 'min_knn_none',\n",
       "       'med_knn_BORUTA', 'med_knn_MI', 'med_knn_none'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metody preprocessingu\n",
    "transformed_df['Preprocessing Method'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametry: dla każdego zbioru danych i każdej metody preprocessingu rozważanych jest 7 kombinacji hiperparametrów (inne dla każdego zbioru danych). Są to kolejno:\n",
    "- domyślne hiperparametry (pierwszy wiersz)\n",
    "- trzy najlepsze hiperparametry (trzy kolejne wiersze)\n",
    "- trzy najgorsze hiperparametry (trzy ostatnie wiersze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21408\\3597059964.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  default_df = banknote_authentication_df[transformed_df['Hyperparameters']== {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}].reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Preprocessing Method</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.23387097 0.19565217], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.16935484 0.13768116], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_MI</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.13709677 0.10869565], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_none</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.15322581 0.10869565], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>med_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.04032258 0.06521739], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>med_knn_MI</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.24193548 0.14492754], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.19354839 0.10144928], [0.    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset Name Preprocessing Method  \\\n",
       "0  banknote-authentication          unprocessed   \n",
       "1  banknote-authentication       min_knn_BORUTA   \n",
       "2  banknote-authentication           min_knn_MI   \n",
       "3  banknote-authentication         min_knn_none   \n",
       "4  banknote-authentication       med_knn_BORUTA   \n",
       "5  banknote-authentication           med_knn_MI   \n",
       "6  banknote-authentication         med_knn_none   \n",
       "\n",
       "                                     Hyperparameters  \\\n",
       "0  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "1  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "2  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "3  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "4  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "5  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "6  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "\n",
       "                                             Results  \n",
       "0  [[[[0.         0.23387097 0.19565217], [0.    ...  \n",
       "1  [[[[0.         0.16935484 0.13768116], [0.    ...  \n",
       "2  [[[[0.         0.13709677 0.10869565], [0.    ...  \n",
       "3  [[[[0.         0.15322581 0.10869565], [0.    ...  \n",
       "4  [[[[0.         0.04032258 0.06521739], [0.    ...  \n",
       "5  [[[[0.         0.24193548 0.14492754], [0.    ...  \n",
       "6  [[[[0.         0.19354839 0.10144928], [0.    ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Załóżmy, że interesują nas wyniki dla zbioru 'banknote-authentication' i różnych metod preprocessingu, ale z domyślnymi hiperparametrami\n",
    "\n",
    "banknote_authentication_df = transformed_df[transformed_df['Dataset Name'] == 'banknote-authentication'].reset_index(drop=True)\n",
    "default_df = banknote_authentication_df[transformed_df['Hyperparameters']== {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}].reset_index(drop=True)\n",
    "default_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21408\\2518808266.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  min_knn_BORUTA_df = banknote_authentication_df[transformed_df['Preprocessing Method'] == \"min_knn_BORUTA\"].reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Preprocessing Method</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.16935484 0.13768116], [0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 6, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.16935484 0.19565217], [0.0555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 28, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.3125     0.44354839 0.44202899], [0.3888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.375      0.44354839 0.44202899], [0.3888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.4375     0.44354839 0.44202899], [0.4444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 46, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.375      0.44354839 0.44202899], [0.4444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>min_knn_BORUTA</td>\n",
       "      <td>{'min_samples_split': 47, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.4375     0.55645161 0.55797101], [0.5   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset Name Preprocessing Method  \\\n",
       "0  banknote-authentication       min_knn_BORUTA   \n",
       "1  banknote-authentication       min_knn_BORUTA   \n",
       "2  banknote-authentication       min_knn_BORUTA   \n",
       "3  banknote-authentication       min_knn_BORUTA   \n",
       "4  banknote-authentication       min_knn_BORUTA   \n",
       "5  banknote-authentication       min_knn_BORUTA   \n",
       "6  banknote-authentication       min_knn_BORUTA   \n",
       "\n",
       "                                     Hyperparameters  \\\n",
       "0  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "1  {'min_samples_split': 6, 'min_samples_leaf': 1...   \n",
       "2  {'min_samples_split': 28, 'min_samples_leaf': ...   \n",
       "3  {'min_samples_split': 20, 'min_samples_leaf': ...   \n",
       "4  {'min_samples_split': 50, 'min_samples_leaf': ...   \n",
       "5  {'min_samples_split': 46, 'min_samples_leaf': ...   \n",
       "6  {'min_samples_split': 47, 'min_samples_leaf': ...   \n",
       "\n",
       "                                             Results  \n",
       "0  [[[[0.         0.16935484 0.13768116], [0.    ...  \n",
       "1  [[[[0.         0.16935484 0.19565217], [0.0555...  \n",
       "2  [[[[0.3125     0.44354839 0.44202899], [0.3888...  \n",
       "3  [[[[0.375      0.44354839 0.44202899], [0.3888...  \n",
       "4  [[[[0.4375     0.44354839 0.44202899], [0.4444...  \n",
       "5  [[[[0.375      0.44354839 0.44202899], [0.4444...  \n",
       "6  [[[[0.4375     0.55645161 0.55797101], [0.5   ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Załóżmy, że interesują nas wyniki dla zbioru 'banknote-authentication' i metody preprocessingu 'min_knn_BORUTA', ale z różnymi hiperparametrami\n",
    "min_knn_BORUTA_df = banknote_authentication_df[transformed_df['Preprocessing Method'] == \"min_knn_BORUTA\"].reset_index(drop=True)\n",
    "min_knn_BORUTA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeśli chcemy teraz rozważać osobno wyniki dla różnych hiperparametrów:\n",
    "default = min_knn_BORUTA_df.iloc[0]['Results'] # pierwszy wiersz to domyślne hiperparametry \n",
    "max1 = min_knn_BORUTA_df.iloc[1]['Results'] # hiperparametry max1\n",
    "max2 = min_knn_BORUTA_df.iloc[2]['Results'] # hiperparametry max2\n",
    "max3 = min_knn_BORUTA_df.iloc[3]['Results'] # hiperparametry max3\n",
    "min1 = min_knn_BORUTA_df.iloc[4]['Results'] # hiperparametry min1\n",
    "min2 = min_knn_BORUTA_df.iloc[5]['Results'] # hiperparametry min2\n",
    "min3 = min_knn_BORUTA_df.iloc[6]['Results'] # hiperparametry min3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 70, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Interpretacja results - na przykładzie default\n",
    "default.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results to 4-wymiarowy array:\n",
    "- pierwszy wymiar (0-4): numer zewnętrznego splitu\n",
    "- drugi wymiar (0-4) : numer wewnętrznego splitu\n",
    "- trzeci wymiar (0-69): numer anchora (aby sprawdzić jego wartość wystarczy sprawdzić anchor_list_denser na tej pozycji)\n",
    "- czwarty wymiar (0-2): 0 - training set, 1 - validation set, 2 - test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10483871, 0.05645161, 0.05645161, 0.07258065, 0.13709677],\n",
       "       [0.05645161, 0.09677419, 0.08870968, 0.02419355, 0.13709677],\n",
       "       [0.05645161, 0.08870968, 0.12903226, 0.13709677, 0.09677419],\n",
       "       [0.19354839, 0.07258065, 0.0483871 , 0.08064516, 0.07258065],\n",
       "       [0.17741935, 0.05645161, 0.17741935, 0.07258065, 0.04032258]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wyniki dla wszystkich splitów dla anchoru o indeksie 20 na zbiorze walidacyjnym\n",
    "train_val_test = 1\n",
    "default[:, :, 20, train_val_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16935484, 0.16935484, 0.16129032, 0.16129032, 0.17741935,\n",
       "       0.19354839, 0.19354839, 0.19354839, 0.19354839, 0.18548387,\n",
       "       0.16129032, 0.18548387, 0.12903226, 0.10483871, 0.10483871,\n",
       "       0.10483871, 0.10483871, 0.09677419, 0.10483871, 0.10483871,\n",
       "       0.10483871, 0.10483871, 0.10483871, 0.05645161, 0.08064516,\n",
       "       0.06451613, 0.07258065, 0.07258065, 0.07258065, 0.04032258,\n",
       "       0.08064516, 0.06451613, 0.05645161, 0.05645161, 0.08870968,\n",
       "       0.05645161, 0.05645161, 0.0483871 , 0.04032258, 0.03225806,\n",
       "       0.04032258, 0.04032258, 0.02419355, 0.00806452, 0.04032258,\n",
       "       0.01612903, 0.02419355, 0.01612903, 0.04032258,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wyniki na wszystkich anchorach dla splitu zewnętrzengo o indeksie 0 i wewnętrznego o indeksie 0\n",
    "default[0, 0, :, train_val_test]\n",
    "# od pewnego momentu są Nan, bo osiągneliśmy maksymalny rozmiar próbki treningowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21408\\2726961383.py:2: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(default[:, :, :, train_val_test], axis=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18      , 0.1816129 , 0.17290323, 0.17258065, 0.16935484,\n",
       "       0.15612903, 0.14870968, 0.14354839, 0.13612903, 0.13677419,\n",
       "       0.14193548, 0.13193548, 0.12548387, 0.11548387, 0.11935484,\n",
       "       0.11129032, 0.10645161, 0.10064516, 0.09774194, 0.09096774,\n",
       "       0.09322581, 0.08      , 0.08225806, 0.07322581, 0.07258065,\n",
       "       0.07032258, 0.07290323, 0.06322581, 0.06096774, 0.05419355,\n",
       "       0.05354839, 0.04870968, 0.04258065, 0.04225806, 0.04064516,\n",
       "       0.03645161, 0.03580645, 0.03129032, 0.03193548, 0.02967742,\n",
       "       0.03064516, 0.02741935, 0.02580645, 0.02322581, 0.02387097,\n",
       "       0.02032258, 0.02032258, 0.02064516, 0.02      ,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Średnie wyniki na wszystkich anchorach dla wszystkich splitów na zbiorze walidacyjnym - de facto z tych danych robimy wykres LC\n",
    "np.nanmean(default[:, :, :, train_val_test], axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21408\\2522236158.py:1: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(max1[:, :, :, train_val_test] + max2[:, :, :, train_val_test] + max3[:, :, :, train_val_test], axis=(0, 1)) / 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3731401 , 0.37681159, 0.2821256 , 0.28995169, 0.28096618,\n",
       "       0.28038647, 0.27729469, 0.17342995, 0.18193237, 0.16975845,\n",
       "       0.16415459, 0.15951691, 0.15942029, 0.15130435, 0.14531401,\n",
       "       0.14347826, 0.14376812, 0.1410628 , 0.14048309, 0.1315942 ,\n",
       "       0.1257971 , 0.12      , 0.12280193, 0.11536232, 0.11072464,\n",
       "       0.10898551, 0.09980676, 0.09487923, 0.09188406, 0.08753623,\n",
       "       0.08676329, 0.07613527, 0.07004831, 0.06541063, 0.06057971,\n",
       "       0.05777778, 0.05623188, 0.05256039, 0.04869565, 0.04444444,\n",
       "       0.03797101, 0.03884058, 0.03487923, 0.03381643, 0.03207729,\n",
       "       0.02975845, 0.02647343, 0.02714976, 0.02705314,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jeśli chcemy stworzyć wykres uśrednionej LC dla najlepszych hiperparametów:\n",
    "np.nanmean(max1[:, :, :, train_val_test] + max2[:, :, :, train_val_test] + max3[:, :, :, train_val_test], axis=(0, 1)) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Policzenie całek dla krzywych LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21408\\2201482669.py:7: RuntimeWarning: Mean of empty slice\n",
      "  y_values = np.nanmean(results[:, :, :, train_val_test], axis=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "# Liczy całki osobno  dla train/valid/test\n",
    "integrals = [[], [], []]\n",
    "for idx, row in transformed_df.iterrows():\n",
    "    results = row[\"Results\"]\n",
    "    for train_val_test in range(3):\n",
    "        try:\n",
    "            y_values = np.nanmean(results[:, :, :, train_val_test], axis=(0, 1))\n",
    "            value = LC_integral_value(y_values)\n",
    "        except Exception:\n",
    "            value = np.nan\n",
    "        integrals[train_val_test].append(value)\n",
    "\n",
    "# Dodajemy kolumnę do ramki danych\n",
    "transformed_df[\"Integral_train\"] = integrals[0]\n",
    "transformed_df['Integral_valid'] = integrals[1]\n",
    "transformed_df['Integral_test'] = integrals[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Preprocessing Method</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Results</th>\n",
       "      <th>Integral_train</th>\n",
       "      <th>Integral_valid</th>\n",
       "      <th>Integral_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.23387097 0.19565217], [0.    ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039602</td>\n",
       "      <td>0.042920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 6, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.16935484 0.10144928], [0.    ...</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.041737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 28, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5        0.44354839 0.44202899], [0.4444...</td>\n",
       "      <td>0.037805</td>\n",
       "      <td>0.067238</td>\n",
       "      <td>0.071462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5        0.44354839 0.44202899], [0.4444...</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>0.062341</td>\n",
       "      <td>0.066377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>unprocessed</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5        0.44354839 0.44202899], [0.5   ...</td>\n",
       "      <td>0.112081</td>\n",
       "      <td>0.131164</td>\n",
       "      <td>0.153786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 15, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.25 0.3  0.3 ], [0.27777778 0.3        0....</td>\n",
       "      <td>0.209097</td>\n",
       "      <td>0.300858</td>\n",
       "      <td>0.295495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 52, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.5 0.3 0.3], [0.44444444 0.3        0.3  ...</td>\n",
       "      <td>0.221175</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.291626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 8, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.125      0.36666667 0.32      ], [0.1111...</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>0.317352</td>\n",
       "      <td>0.312016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 14, 'min_samples_leaf': ...</td>\n",
       "      <td>[[[[0.0625     0.24444444 0.34      ], [0.2222...</td>\n",
       "      <td>0.104053</td>\n",
       "      <td>0.312906</td>\n",
       "      <td>0.299889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>credit-g-mod</td>\n",
       "      <td>med_knn_none</td>\n",
       "      <td>{'min_samples_split': 6, 'min_samples_leaf': 1...</td>\n",
       "      <td>[[[[0.         0.38888889 0.39      ], [0.0555...</td>\n",
       "      <td>0.067418</td>\n",
       "      <td>0.314140</td>\n",
       "      <td>0.313257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset Name Preprocessing Method  \\\n",
       "0    banknote-authentication          unprocessed   \n",
       "1    banknote-authentication          unprocessed   \n",
       "2    banknote-authentication          unprocessed   \n",
       "3    banknote-authentication          unprocessed   \n",
       "4    banknote-authentication          unprocessed   \n",
       "..                       ...                  ...   \n",
       "485             credit-g-mod         med_knn_none   \n",
       "486             credit-g-mod         med_knn_none   \n",
       "487             credit-g-mod         med_knn_none   \n",
       "488             credit-g-mod         med_knn_none   \n",
       "489             credit-g-mod         med_knn_none   \n",
       "\n",
       "                                       Hyperparameters  \\\n",
       "0    {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
       "1    {'min_samples_split': 6, 'min_samples_leaf': 1...   \n",
       "2    {'min_samples_split': 28, 'min_samples_leaf': ...   \n",
       "3    {'min_samples_split': 20, 'min_samples_leaf': ...   \n",
       "4    {'min_samples_split': 50, 'min_samples_leaf': ...   \n",
       "..                                                 ...   \n",
       "485  {'min_samples_split': 15, 'min_samples_leaf': ...   \n",
       "486  {'min_samples_split': 52, 'min_samples_leaf': ...   \n",
       "487  {'min_samples_split': 8, 'min_samples_leaf': 1...   \n",
       "488  {'min_samples_split': 14, 'min_samples_leaf': ...   \n",
       "489  {'min_samples_split': 6, 'min_samples_leaf': 1...   \n",
       "\n",
       "                                               Results  Integral_train  \\\n",
       "0    [[[[0.         0.23387097 0.19565217], [0.    ...        0.000000   \n",
       "1    [[[[0.         0.16935484 0.10144928], [0.    ...        0.002975   \n",
       "2    [[[[0.5        0.44354839 0.44202899], [0.4444...        0.037805   \n",
       "3    [[[[0.5        0.44354839 0.44202899], [0.4444...        0.026701   \n",
       "4    [[[[0.5        0.44354839 0.44202899], [0.5   ...        0.112081   \n",
       "..                                                 ...             ...   \n",
       "485  [[[[0.25 0.3  0.3 ], [0.27777778 0.3        0....        0.209097   \n",
       "486  [[[[0.5 0.3 0.3], [0.44444444 0.3        0.3  ...        0.221175   \n",
       "487  [[[[0.125      0.36666667 0.32      ], [0.1111...        0.059128   \n",
       "488  [[[[0.0625     0.24444444 0.34      ], [0.2222...        0.104053   \n",
       "489  [[[[0.         0.38888889 0.39      ], [0.0555...        0.067418   \n",
       "\n",
       "     Integral_valid  Integral_test  \n",
       "0          0.039602       0.042920  \n",
       "1          0.037933       0.041737  \n",
       "2          0.067238       0.071462  \n",
       "3          0.062341       0.066377  \n",
       "4          0.131164       0.153786  \n",
       "..              ...            ...  \n",
       "485        0.300858       0.295495  \n",
       "486        0.294862       0.291626  \n",
       "487        0.317352       0.312016  \n",
       "488        0.312906       0.299889  \n",
       "489        0.314140       0.313257  \n",
       "\n",
       "[490 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
